2017-10-02 19:05:40 [py.warnings] WARNING: c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\pymysql\cursors.py:166: Warning: (1300, "Invalid utf8 character string: 'F09F99'")
  result = self._query(query)

2017-10-02 19:05:40 [py.warnings] WARNING: c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\pymysql\cursors.py:166: Warning: (1366, "Incorrect string value: '\\xF0\\x9F\\x99\\x82\\xEC\\x98...' for column 'text' at row 1")
  result = self._query(query)

2017-10-02 19:07:29 [py.warnings] WARNING: c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\pymysql\cursors.py:166: Warning: (1300, "Invalid utf8 character string: 'F09F90'")
  result = self._query(query)

2017-10-02 19:07:29 [py.warnings] WARNING: c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\pymysql\cursors.py:166: Warning: (1366, "Incorrect string value: '\\xF0\\x9F\\x90\\xB8' for column 'title' at row 1")
  result = self._query(query)

2017-10-02 19:10:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://web.humoruniv.com/board/humor/list.html?table=poll&pg=7> (referer: None)
Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\CapstoneDesign\Damoa\Git_Crawler\DamoaCrawler\Crawler\spiders\HumorUniv.py", line 116, in parse_site
    dateTmp_post = datetime.strptime(item['date'], '%Y-%m-%d %H:%M:%S')
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '202016-12-31 22:20:00' does not match format '%Y-%m-%d %H:%M:%S'
2017-10-02 19:10:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bbs.ruliweb.com/ps/board/299999/list?page=4> (referer: None)
Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\CapstoneDesign\Damoa\Git_Crawler\DamoaCrawler\Crawler\spiders\ruliweb.py", line 68, in parse
    item['link'] = select.xpath('td/div[@class="relative"]/a/@href').extract()[0]
IndexError: list index out of range
2017-10-02 19:11:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://web.humoruniv.com/board/humor/list.html?table=poll&pg=8> (referer: None)
Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\CapstoneDesign\Damoa\Git_Crawler\DamoaCrawler\Crawler\spiders\HumorUniv.py", line 116, in parse_site
    dateTmp_post = datetime.strptime(item['date'], '%Y-%m-%d %H:%M:%S')
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data '202016-12-21 13:22:00' does not match format '%Y-%m-%d %H:%M:%S'
2017-10-02 19:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bbs.ruliweb.com/ps/board/300143/list?cate=2&page=3> (referer: None)
Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\CapstoneDesign\Damoa\Git_Crawler\DamoaCrawler\Crawler\spiders\ruliweb.py", line 78, in parse
    dateTmp = "".join(postUrl.find(name="span", attrs={"class": "regdate"}).text.replace("(","").replace(")",""))
AttributeError: 'NoneType' object has no attribute 'text'
2017-10-02 19:13:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.clien.net/service/board/lecture?&od=T31&po=2> (referer: None)
Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 964, in send
    self.connect()
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x074BF670>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\adapters.py", line 440, in send
    timeout=timeout
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='www.clien.net', port=80): Max retries exceeded with url: /service/board/lecture/11213821?po=2&od=T31&sk=&sv=&category=&groupCd=&articlePeriod=default (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x074BF670>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\CapstoneDesign\Damoa\Git_Crawler\DamoaCrawler\Crawler\spiders\Clien.py", line 58, in parse
    postUrl = BeautifulSoup(requests.get(item['link']).content, "html.parser")
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\sessions.py", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\sessions.py", line 618, in send
    r = adapter.send(request, **kwargs)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\adapters.py", line 508, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='www.clien.net', port=80): Max retries exceeded with url: /service/board/lecture/11213821?po=2&od=T31&sk=&sv=&category=&groupCd=&articlePeriod=default (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x074BF670>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다',))
2017-10-02 19:13:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bbs.ruliweb.com/ps/board/299999/list?page=5> (referer: None)
Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\CapstoneDesign\Damoa\Git_Crawler\DamoaCrawler\Crawler\spiders\ruliweb.py", line 68, in parse
    item['link'] = select.xpath('td/div[@class="relative"]/a/@href').extract()[0]
IndexError: list index out of range
2017-10-02 19:14:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.clien.net/service/board/bug?&od=T31&po=1> (referer: None)
Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 964, in send
    self.connect()
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x05E259F0>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\adapters.py", line 440, in send
    timeout=timeout
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='www.clien.net', port=80): Max retries exceeded with url: /service/board/bug/11041008?po=1&od=T31&sk=&sv=&category=&groupCd=&articlePeriod=default (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x05E259F0>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\CapstoneDesign\Damoa\Git_Crawler\DamoaCrawler\Crawler\spiders\Clien.py", line 58, in parse
    postUrl = BeautifulSoup(requests.get(item['link']).content, "html.parser")
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\sessions.py", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\sessions.py", line 618, in send
    r = adapter.send(request, **kwargs)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\adapters.py", line 508, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='www.clien.net', port=80): Max retries exceeded with url: /service/board/bug/11041008?po=1&od=T31&sk=&sv=&category=&groupCd=&articlePeriod=default (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x05E259F0>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다',))
2017-10-02 19:14:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bbs.ruliweb.com/ps/board/1020/list?page=5> (referer: None)
Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\CapstoneDesign\Damoa\Git_Crawler\DamoaCrawler\Crawler\spiders\ruliweb.py", line 78, in parse
    dateTmp = "".join(postUrl.find(name="span", attrs={"class": "regdate"}).text.replace("(","").replace(")",""))
AttributeError: 'NoneType' object has no attribute 'text'
2017-10-02 19:17:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://clien.net/service/board/use?&od=T31&po=7>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:17:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://clien.net/service/board/bug?&od=T31&po=7>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:17:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://clien.net/service/board/useful?&od=T31&po=7>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:17:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://clien.net/service/board/park?&od=T31&po=8>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:17:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://clien.net/service/board/pds?&od=T31&po=7>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bbs.ruliweb.com/ps/board/300143/list?cate=2&page=5> (referer: None)
Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\http\client.py", line 964, in send
    self.connect()
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x061A5430>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\adapters.py", line 440, in send
    timeout=timeout
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='bbs.ruliweb.com', port=80): Max retries exceeded with url: /ps/board/300143/read/34942141?cate=2&page=5 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x061A5430>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\CapstoneDesign\Damoa\Git_Crawler\DamoaCrawler\Crawler\spiders\ruliweb.py", line 71, in parse
    postUrl = BeautifulSoup(requests.get(item['link']).content, "html.parser")
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\sessions.py", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\sessions.py", line 618, in send
    r = adapter.send(request, **kwargs)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\requests\adapters.py", line 508, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='bbs.ruliweb.com', port=80): Max retries exceeded with url: /ps/board/300143/read/34942141?cate=2&page=5 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x061A5430>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다',))
2017-10-02 19:18:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://clien.net/service/board/chehum?&od=T31&po=8>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:19:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://clien.net/service/board/use?&od=T31&po=8>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:19:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/lecture?&od=T31&po=1>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:21:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bbs.ruliweb.com/ps/board/299999/list?page=6> (referer: None)
Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\CapstoneDesign\Damoa\Git_Crawler\DamoaCrawler\Crawler\spiders\ruliweb.py", line 68, in parse
    item['link'] = select.xpath('td/div[@class="relative"]/a/@href').extract()[0]
IndexError: list index out of range
2017-10-02 19:23:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://bbs.ruliweb.com/ps/board/300406/list?page=5>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2017-10-02 19:23:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/news?&od=T31&po=5>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:23:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/news?&od=T31&po=7>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:23:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/news?&od=T31&po=6>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:23:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/bug?&od=T31&po=5>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:23:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/kin?&od=T31&po=6>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:23:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/useful?&od=T31&po=6>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:23:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/park?&od=T31&po=6>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:23:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/chehum?&od=T31&po=5>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:23:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bbs.ruliweb.com/ps/board/299999/list?page=7> (referer: None)
Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\CapstoneDesign\Damoa\Git_Crawler\DamoaCrawler\Crawler\spiders\ruliweb.py", line 68, in parse
    item['link'] = select.xpath('td/div[@class="relative"]/a/@href').extract()[0]
IndexError: list index out of range
2017-10-02 19:24:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bbs.ruliweb.com/ps/board/299999/list?page=8> (referer: None)
Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\CapstoneDesign\Damoa\Git_Crawler\DamoaCrawler\Crawler\spiders\ruliweb.py", line 68, in parse
    item['link'] = select.xpath('td/div[@class="relative"]/a/@href').extract()[0]
IndexError: list index out of range
2017-10-02 19:24:49 [py.warnings] WARNING: c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\pymysql\cursors.py:166: Warning: (1300, "Invalid utf8 character string: 'F09F98'")
  result = self._query(query)

2017-10-02 19:24:50 [py.warnings] WARNING: c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\pymysql\cursors.py:166: Warning: (1366, "Incorrect string value: '\\xF0\\x9F\\x98\\x83' for column 'text' at row 1")
  result = self._query(query)

2017-10-02 19:25:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/pds?&od=T31&po=8>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:25:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/news?&od=T31&po=8>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:25:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/pds?&od=T31&po=6>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:25:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/bug?&od=T31&po=6>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:25:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/chehum?&od=T31&po=7>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:25:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/lecture?&od=T31&po=8>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:25:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/lecture?&od=T31&po=7>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:25:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/kin?&od=T31&po=8>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:25:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://bbs.ruliweb.com/ps/board/300145/list?page=6>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2017-10-02 19:25:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://bbs.ruliweb.com/ps/board/300406/list?page=6>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2017-10-02 19:26:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.clien.net/service/board/useful?&od=T31&po=8>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2017-10-02 19:29:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bbs.ruliweb.com/ps/board/299999/list?page=9> (referer: None)
Traceback (most recent call last):
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\xkdlr\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\CapstoneDesign\Damoa\Git_Crawler\DamoaCrawler\Crawler\spiders\ruliweb.py", line 68, in parse
    item['link'] = select.xpath('td/div[@class="relative"]/a/@href').extract()[0]
IndexError: list index out of range
